#+Title: (weak) Perfect Bayesian equilibrium
#+AUTHOR:    Christoph Schottm√ºller
#+Date: 

#+LANGUAGE:  en
#+OPTIONS:   H:2 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport


#+startup: beamer
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: 
#+BEAMER_FRAME_LEVEL: 2
#+latex_header: \mode<beamer>{\useinnertheme{rounded}\usecolortheme{rose}\usecolortheme{dolphin}\setbeamertemplate{navigation symbols}{}\setbeamertemplate{footline}[frame number]{}}
#+latex_header: \mode<beamer>{\usepackage{amsmath}\usepackage{ae,aecompl}\usepackage{sgame,tikz}\usetikzlibrary{trees}}
#+LATEX_HEADER:\let\oldframe\frame\renewcommand\frame[1][allowframebreaks]{\oldframe[#1]}
#+LATEX_HEADER: \setbeamertemplate{frametitle continuation}[from second]

* Introduction
** Introduction
   - previous lecture: market can breakdown if only sellers know product attributes
   - possible countermeasure: try to demonstrate good quality (independent tests etc.)
     - /dynamic/ games of incomplete information
       - dynamic: players take (partially observed) actions sequentially
     - new solution concepts
       - with complete information: dynamics \rightarrow /subgame perfect/ Nash equilibrium (SPNE)
       - with incomplete information: dynamics \rightarrow /(weak) perfect/ Bayesian Nash equilibrium
   - we introduce the equilibrium concept with simpler examples this time and return to the motivation next time
       
* Weak PBE

** When SPNE is too weak
\begin{figure}[h]
\centering
% First, set the overall layout of the tree
% You might need to play with these sizes to ensure nothing overlaps.
\tikzstyle{level 1}=[level distance=1.5cm, sibling distance=3.0cm]
\tikzstyle{level 2}=[level distance=2.0cm, sibling distance=1.5cm]
\tikzstyle{level 3}=[level distance=1.5cm, sibling distance=1.5cm]
\tikzstyle{level 4}=[level distance=1.5cm, sibling distance=1.5cm]
\begin{tikzpicture}
%Start with the parent node, and slowly build out the tree
% with each "child" representing a new level of the diagram
% each "node" represents a labelled (or unlabeled if you 
% want) node in the diagram.
     \node{E}
             child{
               node(a){I}
                  child{
               node{-1,-1}
               edge from parent
               node[left]{fight}
               }
             child{
               node{3,0}
               edge from parent
               node[right]{acc.}
               }
               edge from parent
               node[left]{in1}
               }
             child{
               node(b){I}
                  child{
               node{-1,-1}
               edge from parent
               node[left]{fight}
               }
             child{
               node{2,1}
               edge from parent
               node[right]{acc.}
               }
               edge from parent
               node[right]{in2}
               }
	     child{
	     node{0,2}
	     edge from parent
               node[right]{out}
	     };
\draw [dashed](a)--(b);
\end{tikzpicture}
\end{figure}

- entrant can enter with two technologies (in1 and in2)
- what are the (SP)NE? 
# (in1, acc), (out,fight)
- which SPNE is a (not so) reasonable prediction?
# acc. is a better response than fight for any belief, i.e. I does better with acc. when reaching his info set; sequential rationality suggests I should play acc. but only subgame of game is game itself; hence SPNE has no bite

** Beliefs 
- at every information set $H$ the acting player has to have a "belief" over the nodes in $H$
  - the players assigns probabilities to all decision nodes in his information set
  - these probabilities sum to 1
    
*** System of beliefs
 A system of beliefs $\mu$ assigns to every node $x$ in an extensive form game $\Gamma_E$ a probability $\mu(x)\in[0,1]$ such that $\sum_{y\in H(x)}\mu(y)=1$ (where $H(x)$  is the information set in which $x$ lies).

** Sequential rationality

- sequentially rational: no player wants to change his behavior in some information set given his beliefs and strategies of the other players
  - each player's strategy maximizes expected utility at every information set
  - expected utility is calculated using
    - own beliefs at the information set and
    - strategies of all players

*** Sequential rationality
A strategy profile $\sigma$ is sequentially rational given system of beliefs $\mu$ if for every information set $H$, the player acting at $H$ cannot increase his expected utility by deviating from $\sigma_i$ at $H$:
$$\mathbb{E}[u_i(\sigma_i,\sigma_{-i})|H,\mu]\geq \mathbb{E}[u_i(\tilde\sigma_i,\sigma_{-i})|H,\mu]$$
for all $\tilde\sigma_i$ differing from $\sigma_i$ only at $H$.

*** 							    :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :END:
- which strategy profile is sequentially rational in the previous example game (for which system of beliefs)?

** Why sequential rationality may not be enough

\begin{figure}[h]
\centering
% First, set the overall layout of the tree
% You might need to play with these sizes to ensure nothing overlaps.
\tikzstyle{level 1}=[level distance=1.5cm, sibling distance=3.0cm]
\tikzstyle{level 2}=[level distance=2.0cm, sibling distance=1.5cm]
\tikzstyle{level 3}=[level distance=1.5cm, sibling distance=1.5cm]
\tikzstyle{level 4}=[level distance=1.5cm, sibling distance=1.5cm]
\begin{tikzpicture}
%Start with the parent node, and slowly build out the tree
% with each "child" representing a new level of the diagram
% each "node" represents a labelled (or unlabeled if you 
% want) node in the diagram.
     \node{P1}
             child{
               node(a){P2}
                  child{
               node{-1,1}
               edge from parent
               node[left]{l}
               }
             child{
               node{3,0}
               edge from parent
               node[right]{r}
               }
               edge from parent
               node[left]{L}
               }
             child{
               node(b){P2}
                  child{
               node{1,-1}
               edge from parent
               node[left]{l}
               }
             child{
               node{4,1}
               edge from parent
               node[right]{r}
               }
               edge from parent
               node[right]{R}
               	     };
\draw [dashed](a)--(b);
\end{tikzpicture}
\end{figure}

- is there a belief system such that $(R,l)$ is sequentially rational? 
# yes $\mu=(1,0)$. Problem: not even a Nash equilibrium!

** Weak perfect Bayesian Nash equilibrium
- beliefs should be consistent with the strategies used
   - $prob(x|H,\sigma)=\frac{prob(x|\sigma)}{\sum_{x'\in H}prob(x'|\sigma)}$ if $\sum_{x'\in H}prob(x'|\sigma)>0$ and $x\in H$
   - arbitrary $\mu_H$ if $\sum_{x'\in H}prob(x'|\sigma)=0$

*** Weak perfect Bayesian Nash equilibrium (weak PBE)
A profile of strategies $\sigma$ together with a system of beliefs $\mu$ is a weak PBE in an extensive form game $\Gamma_E$ if 
- $\sigma$ is sequentially rational given $\mu$,
- $\mu$ is derived from $\sigma$ using Bayes' rule at all information sets reached with positive probability under $\sigma$.

*** 							    :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :END:

- weak PBE in previous example?

** incomplete information and Harsanyi's trick I
   - so far: "imperfect information" (i.e. do not observe another player's prior actions)
   - what about "incomplete information" (i.e. do not observe another player's "type")?
   - example
     - buyer has private information about his valuation for one indivisible good
       - valuation is either $v_h$ or $v_l$ (both with probability 1/2)
     - monopoly seller with zero costs sets a price $p\in\{p_h,p_l\}$
     - after observing $p$ buyer decides whether to buy or not
   - Harsanyi's trick: introduce artificial player "nature"
     - nature chooses type of buyer (each with probability 1/2)
     - seller chooses price without observing nature's choice
     - buyer chooses to buy or not observing all prior choices
     - taking nature's strategy as fixed, we have a game as before and use wPBE as before


**  incomplete information and Harsanyi's trick II

\begin{figure}[h]
\centering
\hspace*{-1cm}
% First, set the overall layout of the tree
% You might need to play with these sizes to ensure nothing overlaps.
\tikzstyle{level 1}=[level distance=1.25cm, sibling distance=6cm]
\tikzstyle{level 2}=[level distance=1.25cm, sibling distance=3cm]
\tikzstyle{level 3}=[level distance=1.5cm, sibling distance=1.5cm]
\tikzstyle{level 4}=[level distance=1.5cm, sibling distance=1.5cm]
\begin{tikzpicture}
%Start with the parent node, and slowly build out the tree
% with each "child" representing a new level of the diagram
% each "node" represents a labelled (or unlabeled if you 
% want) node in the diagram.
\node{N}
    child{
             node(s1){S}
             child{
               node(a){B}
                  child{
               node{$p_h$,$v_l-p_h$}
               edge from parent
               node[left]{buy}
               }
             child{
               node{0,0}
               edge from parent
               node[right]{not}
               }
               edge from parent
               node[left]{$p_h$}
               }
             child{
               node(b){B}
                  child{
               node{$p_l$,$v_l-p_l$}
               edge from parent
               node[left]{buy}
               }
             child{
               node{$0$,$0$}
               edge from parent
               node[right]{not}
               }
               edge from parent
               node[right]{$p_l$}
               }
           edge from parent
           node[left]{$v_l$}
           }
    child{
         node(s2){S}
             child{
               node(c){B}
                  child{
               node{$p_h$,$v_h-p_h$}
               edge from parent
               node[left]{buy}
               }
             child{
               node{0,0}
               edge from parent
               node[right]{not}
               }
               edge from parent
               node[left]{$p_h$}
               }
             child{
               node(d){B}
                  child{
               node{$p_l$,$v_h-p_l$}
               edge from parent
               node[left]{buy}
               }
             child{
               node{0,0}
               edge from parent
               node[right]{not}
               }
               edge from parent
               node[right]{$p_l$}
               }
           edge from parent
           node[right]{$v_h$}
         };
\draw [dashed](s1)--(s2);
\end{tikzpicture}
%\caption{extensive form game with imperfect information}
%\label{fig:ext_game_imperf_info}
\end{figure}

- assuming $v_h=7$, $v_l=4$, $p_h=5$ and $p_l=3$, determine wPBE
  # seq rationality B: type v_l buys only if p_l while type v_h always buys
  # belief: by Bayes' rule: 1/2, 1/2
  # seq rationality S: expected payoff of $p_h$ is 5/2 while of p_l it is 3, hence only p_l is seq rational

* Example: Behavior based price discrimination

** Behavior based price discrimination I

  - same buyer/seller example but 2 periods
    - buyer can buy 1 unit each period
    - seller can charge different prices each period
    - discounting: payoffs realized in period 2 are discounted with discount factor 3/4

** Behavior based price discrimination II

- timeline
  - period 1:
    - nature chooses buyer's type $v\in\{7,4\}$ each with probability $1/2$
    - seller chooses $p_1\in\{5,3\}$ (not observing $v$)
    - buyer decides whether to buy at price $p_1$, i.e. $b_1\in\{0,1\}$
  - period 2:
    - seller chooses $p_2$ (after observing $b_1$)
    - buyer decides whether to buy at price $p_2$, i.e. $b_2\in\{0,1\}$

- wPBE components
  - seller strategy: $p_1$ and $p_2(p_1,b_1)$
  - buyer strategy: $b_1(p_1,v)$ and $b_2(p_1,b_1,p_2,v)$
  - seller beliefs: $\mu_1$ and $\mu_2(p_1,b_1)$

** Behavior based price discrimination III
- actions in period 2:  
  - sequential rationality: buyer buys in period 2 if and only if price is below his valuation
  - sequential rationality seller: $p_2=5$ if and only if $\mu_2 5\geq 3\;\Leftrightarrow\; \mu_2\geq 3/5$

- beliefs $\mu_2$:
  - what are possible seller beliefs?
    - if both types buy in period 1 (in equilibrium):
      # 1/2 by Bayes' rule after buying; (belief after not buying not determined)
    - if only $v_h$ buys in period 1 (in equilibrium):
      # 1 after buying and 0 after not buying

- buying decision of $v_h$ in period 1:
  - if $p_1=5$ is it optimal to buy or not?
    # always optimal to buy as in worst case payoff is (7-5)*(1+.75)>.75*(7-3) where the latter is the best case payoff of not buying
  - if $p_1=3$ is it optimal to buy or not?
    # even stronger argument as above => buy 

- buying decision of $v_l$ in period 1:
  - if $p_1=5$ is it optimal to buy or not?
    # maximal payoff after buying in period 1 is (4-5)+.75*(4-3)<0 => better not to buy
  - if $p_1=3$ is it optimal to buy or not?
    # minimal payoff after buying is 4-3=1 while maximum payoff when not buying equals .75(4-3)<1 => buy 
- what is the profit maximizing price $p_1$?
    # p_1=3 leads to mu_2=1/2 and p_2=3 and therefore profits of 3*1.75=5.25
    # p_1=5 leads to separation in period 2 and profits of .5*5+.75*(.5*5+.5*3)=5.5  
    
** Behavior based price discrimination IV       
   - wPBE
     - seller: $p_1=5$, $p_2(5,1)=5$, $p_2(5,0)=3$, $p_2(3,1)=p_2(3,0)=3$
     - buyer: buy in each period if and only if valuation is above price
     - beliefs: $\mu_1=1/2$, $\mu_2(5,1)=1$, $\mu_2(5,0)=0$, $\mu_2(3,1)=1/2$, $\mu_2(3,0)=1/2$
   - seller uses period 1 to screen buyer types
   - seller benefits in period 2 from conditioning his prices on purchase history

       
* Example: Privacy and donations
** Privacy and donations I
  - we often draw inferences about other people's attitudes/preferences/character when observing their actions
  - if you know that others will observe and judge your behavior, will you act differently?
  - our example:
    - assumption 1: people donating for a good cause are viewed positively
    - assumption 2: other people are nicer to people they view more positively
    - how will observability of a donation affect donation behavior?
   
** Privacy and donations II: model    
   - player 1 decides how much to donate: $d\in\Re_+$
     - type $t_1$ 
       - player 2's prior: $t_1$ uniformly distributed on $[0,1]$ 
     - payoff: $-(t_1-d)^2+b$
   - after player 1's donation, player 2 chooses an action $b\in[0,1]$
     - payoff: $-(b-t_1)^2$
   - we compare wPBE in two scenarios:
     - player 2 observes $d$ before choosing $b$
     - player 2 does not observe $d$ 

** Privacy and donations III: no observation of $d$
   - wPBE
     - strategies $d(t_1)$ for P1 and $b$ for P2
     - belief $\mu_2$ of P2
   - wPBE belief $\mu_2$:
     \vspace*{0.7cm}
     # no observation => no updating => uniform on [0,1]
   - sequentially rational $b$:
     \vspace*{0.7cm}
     # max_b \int_0^1 -(b-t_1)^2 dt_1 => b=1/2
   - sequentially rational $d$:
     \vspace*{0.7cm}
     # max_d -(t_1-d)^2+1/2  => d=t_1

** Privacy and donations III: observation of $d$
   - wPBE
     - strategies $d(t_1)$ for P1 and $b(d)$ for P2
     - belief $\mu_2(d)$ of P2
     - we will try to find a /separating wPBE/, i.e. each type chooses a different donation $d$
   - belief $\mu_2$ in separating wPBE:
     \vspace*{0.7cm}
     # as every type chooses a different action, type is perfectly inferred
     # let the inverse of d(v) be s
     # i.e. belief puts probability 1 on s(d)
   - sequentially rational $b$:
     \vspace*{0.7cm}
     # max_b -(b-s(d))^2  => b=s(d)
   - sequentially rational $d$:
     # max_d -(t_1-d)^2+s(d)  => first order condition: 2(t_1-d)+s'(d)=0
     # in PBE P2's inference is correct, i.e. t_1=s(d) and the foc becomes the differential equation 2s(d)-2d+s'(d)=0 which is solved by s(d)=d-1/2; inverting gives the strategy d(t_1)=1/2+t_1
 
** Privacy and donations IV
   - same effect can also operate in opposite direction
     - drug addicts are viewed negatively (e.g. on the labor market)
     - should potential employers be allowed to ask for treatment of substance abuse in job interviews? what are the effects?
     
* PBE

** Why "weak" PBE is (sometimes too) weak: unreasonable beliefs

\begin{figure}[h]
\centering
\hspace*{-1cm}
% First, set the overall layout of the tree
% You might need to play with these sizes to ensure nothing overlaps.
\tikzstyle{level 1}=[level distance=1.25cm, sibling distance=6cm]
\tikzstyle{level 2}=[level distance=1.25cm, sibling distance=3cm]
\tikzstyle{level 3}=[level distance=1.5cm, sibling distance=1.5cm]
\tikzstyle{level 4}=[level distance=1.5cm, sibling distance=1.5cm]
\begin{tikzpicture}
%Start with the parent node, and slowly build out the tree
% with each "child" representing a new level of the diagram
% each "node" represents a labelled (or unlabeled if you 
% want) node in the diagram.
\node{N}
    child{
             node(s1){P1}
             child{
               node{$1,10$}
               edge from parent
               node[left]{$x$}
               }
             child{
               node(b){P2}
                  child{
               node{$0,5$}
               edge from parent
               node[left]{$z$}
               }
             child{
               node{$5$,$3$}
               edge from parent
               node[right]{$w$}
               }
               edge from parent
               node[right]{$y$}
               }
           edge from parent
           node[left]{$\frac{1}{2}$}
           }
    child{
         node(s2){P1}
             child{
               node(c){P2}
                  child{
               node{$0$,$5$}
               edge from parent
               node[left]{$z$}
               }
             child{
               node{5,20}
               edge from parent
               node[right]{$w$}
               }
               edge from parent
               node[left]{$y$}
               }
             child{
               node{$1,10$}
               edge from parent
               node[right]{$x$}
               }
           edge from parent
           node[right]{$\frac{1}{2}$}
         };
\draw [dashed](s1)--(s2);
\draw [dashed](b)--(c);
\end{tikzpicture}
%\caption{extensive form game with imperfect information}
%\label{fig:ext_game_imperf_info}
\end{figure}
- one wPBE:
  - strategies: $x$ and $z$
  - beliefs: $\mu_1=(1/2  ,1/2)$, $\mu_2=(0.9,0.1)$
- why is P2's belief inconsistent?
# P2's info set reached if P1 plays y but as P1 doe snot know nature's move this has to be equally probable after each of nature's moves -> reasonable belief is 1/2,1/2
\pause
- \normalsize{(add requirement: some strategy profile leading to off path beliefs has to exist; "structural consistency")}


** Why "weak" PBE is (sometimes too) weak: not subgame perfect
 \begin{figure}[h]
\centering
% First, set the overall layout of the tree
% You might need to play with these sizes to ensure nothing overlaps.
\tikzstyle{level 1}=[level distance=1.25cm, sibling distance=3.5cm]
\tikzstyle{level 2}=[level distance=1.25cm, sibling distance=4.25cm]
\tikzstyle{level 3}=[level distance=1.5cm, sibling distance=1.5cm]
\tikzstyle{level 4}=[level distance=1.5cm, sibling distance=1.5cm]
\begin{tikzpicture}
%Start with the parent node, and slowly build out the tree
% with each "child" representing a new level of the diagram
% each "node" represents a labelled (or unlabeled if you 
% want) node in the diagram.
\node{E}
    child{
             node{E}
             child{
               node(a){I}
                  child{
               node{-3,-1}
               edge from parent
               node[left]{fight}
               }
             child{
               node{1,-2}
               edge from parent
               node[right]{accommodate}
               }
               edge from parent
               node[left]{fight}
               }
             child{
               node(b){I}
                  child{
               node{-2,-1}
               edge from parent
               node[left]{fight}
               }
             child{
               node{3,1}
               edge from parent
               node[right]{accomodate}
               }
               edge from parent
               node[right]{accomodate}
               }
           edge from parent
           node[left]{in}
           }
    child{
         node{0,2}
         edge from parent
         node[right]{out}
         };
\draw [dashed](a)--(b);
\end{tikzpicture}
%\caption{extensive form game with imperfect information}
%\label{fig:ext_game_imperf_info}
\end{figure}

- with which belief system would (out+accommodate, fight) be a weak PBE? 
- is (out+accommodate, fight) subgame perfect NE?
\pause
- (add requirement "weak PBE in every subgame")

** Perfect Bayesian equilibrium
   - caution: different authors use different ways of defining /perfect Bayesian equilibrium/
***  perfect Bayesian equilibrium    (PBE)
A perfect Bayesian equilibrium is a weak perfect Bayesian equilibrium which \linebreak
(i) induces a weak perfect Bayesian equilibrium in every subgame \linebreak
(ii) satisfies structural consistency, i.e. beliefs at every information set are such that a strategy profile consistent with these beliefs exists.

*** 							    :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :END:

- PBE in previous example?


